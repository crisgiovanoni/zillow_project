{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Estimating Assessed Value of Properties    Using the Zillow Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cris Giovanoni  \n",
    "October 21, 2019\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes  \n",
    "  \n",
    "### Assumptions\n",
    "- Square footage accounted all living, finished spaces. The values **excluded** the following:\n",
    "  - Basement\n",
    "  - Garage\n",
    "  - Yard\n",
    "  - Entire lot\n",
    "- Types of Single Unit housing included in the analysis:\n",
    "   - 261\tSingle Family Residential\n",
    "   - 262\tRural Residence\n",
    "   - 263\tMobile Home\n",
    "   - 264\tTownhouse\n",
    "   - 265\tCluster Home\n",
    "   - 268\tRow House\n",
    "   - 269\tPlanned Unit Development\n",
    "   - 273\tBungalow\n",
    "   - 275\tManufactured, Modular, Prefabricated Homes\n",
    "   - 276\tPatio Home\n",
    "\n",
    "### Workflow\n",
    "- I. Create baseline model\n",
    "- II. Create 立 model, going through entire pipeline\n",
    "- III. Compare baseline model and 立 model using the test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import zillow_util as util"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## I. Create Baseline Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get data from SQL and filter data with the following conditions:\n",
    "tk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "zillow = util.filter_zillow_baseline(util.get_sql_zillow())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separate the features (X) and target (y) columns. Then, split data to train and test, resulting to four data frames with X and y separated and partitioned into two."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = zillow[[\"sqft\",\"bathcnt\",\"bedcnt\"]]\n",
    "y = zillow.propvalue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = util.split_my_data(X, y, 0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scale train and test data with all X.  \n",
    "Scaled X train data will be fitted into to the model later.  \n",
    "Scaled X test data will be used post-modelling phase to test the baseline model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_X_train, scaled_X_test, standard_scaler = util.standard_scaler(X_train, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a linear model with train data, i.e., scaled X data and unscaled y data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lm_base, lm_base_intercept, lm_base_coeff = util.generate_linear_model(scaled_X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)\n",
      "528745.8490634661\n",
      "[ 422257.73320622   73656.54782346 -136593.73861784]\n"
     ]
    }
   ],
   "source": [
    "print(lm_base)\n",
    "print(lm_base_intercept)\n",
    "print(lm_base_coeff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## II. Create  立 Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PROJECT PLAN\n",
    "**PROJECT PLAN** -> ACQUIRE -> PRE-PROCESS -> EXPLORE -> MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PROJECT PLANNING & README\n",
    "Brainstorming ideas, hypotheses, related to how variables might impact or relate to each other, both within independent variables and between the independent variables and dependent variable, and also related to any ideas for new features you may have while first looking at the existing variables and challenge ahead of you.\n",
    "\n",
    "Have a detailed README.md file for anyone who wants to check out your project. In this file should be a description of what the project is, and any instructions necessary for someone else to clone your project and run the code on their own laptop.\n",
    "\n",
    "\"PREDICTIVE POWER\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ACQUIRE\n",
    "PROJECT PLAN -> **ACQUIRE** -> PRE-PROCESS -> EXPLORE -> MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get data from SQL.  \n",
    "Perform initial cleanup by casting columns to appropriate data types.\n",
    "  - Re-type transaction date as a date data type. After which, extract properties whose transaction date fall between May and June 2017.\n",
    "  - Rename columns for efficiency.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "zillow = util.filter_zillow(util.get_sql_zillow())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 15740 entries, 868 to 37865\n",
      "Data columns (total 6 columns):\n",
      "id           15740 non-null int64\n",
      "sqft         15712 non-null float64\n",
      "bathcnt      15740 non-null float64\n",
      "bedcnt       15740 non-null float64\n",
      "transdate    15740 non-null datetime64[ns]\n",
      "propvalue    15740 non-null float64\n",
      "dtypes: datetime64[ns](1), float64(4), int64(1)\n",
      "memory usage: 860.8 KB\n"
     ]
    }
   ],
   "source": [
    "zillow.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PRE-PROCESS\n",
    "PROJECT PLAN -> ACQUIRE -> **PRE-PROCESS** -> EXPLORE -> MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Clean Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look for missing values.\n",
    " - Observations that don't have square footage also don't contain bathroom and bedroom count. Because the values of these features add little to no value to the data, they are dropped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id            0\n",
       "sqft         28\n",
       "bathcnt       0\n",
       "bedcnt        0\n",
       "transdate     0\n",
       "propvalue     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zillow.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sqft</th>\n",
       "      <th>bathcnt</th>\n",
       "      <th>bedcnt</th>\n",
       "      <th>transdate</th>\n",
       "      <th>propvalue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22402</th>\n",
       "      <td>14466991</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2017-05-01</td>\n",
       "      <td>2493444.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23075</th>\n",
       "      <td>13972530</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2017-05-04</td>\n",
       "      <td>270009.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23076</th>\n",
       "      <td>14325627</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2017-05-04</td>\n",
       "      <td>7074075.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23095</th>\n",
       "      <td>12686981</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2017-05-04</td>\n",
       "      <td>5461875.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23861</th>\n",
       "      <td>10746614</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2017-05-08</td>\n",
       "      <td>230876.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24796</th>\n",
       "      <td>14175690</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2017-05-11</td>\n",
       "      <td>157074.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24873</th>\n",
       "      <td>12131538</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2017-05-11</td>\n",
       "      <td>225126.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26411</th>\n",
       "      <td>17292027</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2017-05-18</td>\n",
       "      <td>3210155.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27852</th>\n",
       "      <td>14175815</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2017-05-24</td>\n",
       "      <td>385795.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27931</th>\n",
       "      <td>14430787</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2017-05-25</td>\n",
       "      <td>5126781.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29010</th>\n",
       "      <td>17267536</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2017-05-30</td>\n",
       "      <td>26237.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29377</th>\n",
       "      <td>167687839</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2017-05-31</td>\n",
       "      <td>1842678.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30251</th>\n",
       "      <td>17190620</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2017-06-02</td>\n",
       "      <td>180000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31037</th>\n",
       "      <td>12528751</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2017-06-06</td>\n",
       "      <td>1289097.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31500</th>\n",
       "      <td>14466726</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2017-06-08</td>\n",
       "      <td>1558090.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32181</th>\n",
       "      <td>12055162</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2017-06-12</td>\n",
       "      <td>406100.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32384</th>\n",
       "      <td>14326442</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2017-06-13</td>\n",
       "      <td>3136161.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33661</th>\n",
       "      <td>14237996</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2017-06-16</td>\n",
       "      <td>626497.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33901</th>\n",
       "      <td>14359299</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2017-06-19</td>\n",
       "      <td>1244873.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34206</th>\n",
       "      <td>13889651</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2017-06-20</td>\n",
       "      <td>125714.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34521</th>\n",
       "      <td>13889433</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2017-06-21</td>\n",
       "      <td>1941143.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34822</th>\n",
       "      <td>13865064</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2017-06-22</td>\n",
       "      <td>2231097.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34998</th>\n",
       "      <td>14469211</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2017-06-22</td>\n",
       "      <td>970000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35225</th>\n",
       "      <td>11496648</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2017-06-23</td>\n",
       "      <td>957014.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36001</th>\n",
       "      <td>14166728</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2017-06-27</td>\n",
       "      <td>1608894.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36560</th>\n",
       "      <td>11640641</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2017-06-28</td>\n",
       "      <td>2077940.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36599</th>\n",
       "      <td>11486198</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2017-06-29</td>\n",
       "      <td>900820.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37803</th>\n",
       "      <td>12179038</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2017-06-30</td>\n",
       "      <td>177668.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              id  sqft  bathcnt  bedcnt  transdate  propvalue\n",
       "22402   14466991   NaN      0.0     0.0 2017-05-01  2493444.0\n",
       "23075   13972530   NaN      0.0     0.0 2017-05-04   270009.0\n",
       "23076   14325627   NaN      0.0     0.0 2017-05-04  7074075.0\n",
       "23095   12686981   NaN      0.0     0.0 2017-05-04  5461875.0\n",
       "23861   10746614   NaN      0.0     0.0 2017-05-08   230876.0\n",
       "24796   14175690   NaN      0.0     0.0 2017-05-11   157074.0\n",
       "24873   12131538   NaN      0.0     0.0 2017-05-11   225126.0\n",
       "26411   17292027   NaN      0.0     0.0 2017-05-18  3210155.0\n",
       "27852   14175815   NaN      0.0     0.0 2017-05-24   385795.0\n",
       "27931   14430787   NaN      0.0     0.0 2017-05-25  5126781.0\n",
       "29010   17267536   NaN      0.0     0.0 2017-05-30    26237.0\n",
       "29377  167687839   NaN      0.0     0.0 2017-05-31  1842678.0\n",
       "30251   17190620   NaN      0.0     0.0 2017-06-02   180000.0\n",
       "31037   12528751   NaN      0.0     0.0 2017-06-06  1289097.0\n",
       "31500   14466726   NaN      0.0     0.0 2017-06-08  1558090.0\n",
       "32181   12055162   NaN      0.0     0.0 2017-06-12   406100.0\n",
       "32384   14326442   NaN      0.0     0.0 2017-06-13  3136161.0\n",
       "33661   14237996   NaN      0.0     0.0 2017-06-16   626497.0\n",
       "33901   14359299   NaN      0.0     0.0 2017-06-19  1244873.0\n",
       "34206   13889651   NaN      0.0     0.0 2017-06-20   125714.0\n",
       "34521   13889433   NaN      0.0     0.0 2017-06-21  1941143.0\n",
       "34822   13865064   NaN      0.0     0.0 2017-06-22  2231097.0\n",
       "34998   14469211   NaN      0.0     0.0 2017-06-22   970000.0\n",
       "35225   11496648   NaN      0.0     0.0 2017-06-23   957014.0\n",
       "36001   14166728   NaN      0.0     0.0 2017-06-27  1608894.0\n",
       "36560   11640641   NaN      0.0     0.0 2017-06-28  2077940.0\n",
       "36599   11486198   NaN      0.0     0.0 2017-06-29   900820.0\n",
       "37803   12179038   NaN      0.0     0.0 2017-06-30   177668.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nulls = zillow[zillow.sqft.isnull()]\n",
    "nulls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "zillow = zillow.dropna(subset=['sqft']) #Drop NaNs in the sqft column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look for duplicates.\n",
    " - There are 5 duplicates.\n",
    " - All duplicates point to the same property (same sqft, nos. of bathroom and bedroom, and property value); the only difference is the transaction date.\n",
    " - Observations with more recent transaction date are kept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sqft</th>\n",
       "      <th>bathcnt</th>\n",
       "      <th>bedcnt</th>\n",
       "      <th>transdate</th>\n",
       "      <th>propvalue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23560</th>\n",
       "      <td>14074415</td>\n",
       "      <td>1025.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2017-05-05</td>\n",
       "      <td>48107.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23561</th>\n",
       "      <td>14074415</td>\n",
       "      <td>1025.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2017-05-12</td>\n",
       "      <td>48107.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24099</th>\n",
       "      <td>162960529</td>\n",
       "      <td>2459.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2017-05-09</td>\n",
       "      <td>479000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24100</th>\n",
       "      <td>162960529</td>\n",
       "      <td>2459.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2017-05-26</td>\n",
       "      <td>479000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27348</th>\n",
       "      <td>17280166</td>\n",
       "      <td>1816.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2017-05-23</td>\n",
       "      <td>350701.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27349</th>\n",
       "      <td>17280166</td>\n",
       "      <td>1816.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2017-06-15</td>\n",
       "      <td>350701.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27420</th>\n",
       "      <td>14254548</td>\n",
       "      <td>2126.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2017-05-23</td>\n",
       "      <td>98473.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27421</th>\n",
       "      <td>14254548</td>\n",
       "      <td>2126.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2017-06-12</td>\n",
       "      <td>98473.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30899</th>\n",
       "      <td>11991059</td>\n",
       "      <td>8469.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2017-06-06</td>\n",
       "      <td>2485282.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30900</th>\n",
       "      <td>11991059</td>\n",
       "      <td>8469.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2017-06-09</td>\n",
       "      <td>2485282.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30901</th>\n",
       "      <td>11991059</td>\n",
       "      <td>8469.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2017-06-13</td>\n",
       "      <td>2485282.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              id    sqft  bathcnt  bedcnt  transdate  propvalue\n",
       "23560   14074415  1025.0      1.0     2.0 2017-05-05    48107.0\n",
       "23561   14074415  1025.0      1.0     2.0 2017-05-12    48107.0\n",
       "24099  162960529  2459.0      4.0     4.0 2017-05-09   479000.0\n",
       "24100  162960529  2459.0      4.0     4.0 2017-05-26   479000.0\n",
       "27348   17280166  1816.0      3.0     4.0 2017-05-23   350701.0\n",
       "27349   17280166  1816.0      3.0     4.0 2017-06-15   350701.0\n",
       "27420   14254548  2126.0      2.0     4.0 2017-05-23    98473.0\n",
       "27421   14254548  2126.0      2.0     4.0 2017-06-12    98473.0\n",
       "30899   11991059  8469.0      6.0    12.0 2017-06-06  2485282.0\n",
       "30900   11991059  8469.0      6.0    12.0 2017-06-09  2485282.0\n",
       "30901   11991059  8469.0      6.0    12.0 2017-06-13  2485282.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dups = zillow[zillow.duplicated(subset=[\"id\"])]\n",
    "dups_ids = list(dups.id)\n",
    "\n",
    "mask = ~zillow.id.isin(dups_ids) #Returns True for non-duplicates\n",
    "zillow.loc[~mask] #See what the duplicates contain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sqft</th>\n",
       "      <th>bathcnt</th>\n",
       "      <th>bedcnt</th>\n",
       "      <th>transdate</th>\n",
       "      <th>propvalue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23561</th>\n",
       "      <td>14074415</td>\n",
       "      <td>1025.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2017-05-12</td>\n",
       "      <td>48107.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24100</th>\n",
       "      <td>162960529</td>\n",
       "      <td>2459.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2017-05-26</td>\n",
       "      <td>479000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27421</th>\n",
       "      <td>14254548</td>\n",
       "      <td>2126.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2017-06-12</td>\n",
       "      <td>98473.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30901</th>\n",
       "      <td>11991059</td>\n",
       "      <td>8469.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2017-06-13</td>\n",
       "      <td>2485282.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27349</th>\n",
       "      <td>17280166</td>\n",
       "      <td>1816.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2017-06-15</td>\n",
       "      <td>350701.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              id    sqft  bathcnt  bedcnt  transdate  propvalue\n",
       "23561   14074415  1025.0      1.0     2.0 2017-05-12    48107.0\n",
       "24100  162960529  2459.0      4.0     4.0 2017-05-26   479000.0\n",
       "27421   14254548  2126.0      2.0     4.0 2017-06-12    98473.0\n",
       "30901   11991059  8469.0      6.0    12.0 2017-06-13  2485282.0\n",
       "27349   17280166  1816.0      3.0     4.0 2017-06-15   350701.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zillow = zillow.sort_values(\"transdate\").drop_duplicates('id',keep='last')\n",
    "zillow.loc[~mask] #Check if duplicates are indeed dropped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Split-Scale Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SPLIT**\n",
    "1. Separate the features (X) and target (y) columns.\n",
    "2. Using `split_my_data` function from `zillow.util`, split further to train and test, resulting to four data frames with X and y separated and partitioned into two-train and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = zillow[[\"sqft\",\"bathcnt\",\"bedcnt\"]]\n",
    "y = zillow.propvalue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = util.split_my_data(X, y, 0.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SCALE**  \n",
    "1. Scale all feature data, i.e., X_train and X_test, using the `standard_scaler` function from `zillow.util`.\n",
    "    - _Note:_ Features are scaled to mimic a normal distribution because Pearson's R will be obtained later.\n",
    "2. Scale X_train data. It will be fitted into to the model later.  \n",
    "3. Scale X_test data. It will be used post-modelling phase to test 立 model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/data.py:2863: RuntimeWarning: divide by zero encountered in log\n",
      "  loglike = -n_samples / 2 * np.log(x_trans.var())\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'uniform_scaler' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-----------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-99b44a23b05b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mscaled_X_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaled_X_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstandard_scaler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgaussian_scaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/codeup-data-science/ds-methodologies-exercises/zillow_project/zillow_util.py\u001b[0m in \u001b[0;36mgaussian_scaler\u001b[0;34m(X_train, X_test)\u001b[0m\n\u001b[1;32m    187\u001b[0m     \u001b[0mscaled_X_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscaled_X_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    188\u001b[0m     \u001b[0;31m# Scale Train and Convert to a Data Frame\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 189\u001b[0;31m     \u001b[0mscaled_y_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muniform_scaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    190\u001b[0m     \u001b[0mscaled_y_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscaled_X_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mscaled_X_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscaled_X_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgaussian_scaler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'uniform_scaler' is not defined"
     ]
    }
   ],
   "source": [
    "scaled_X_train, scaled_X_test, standard_scaler = util.gaussian_scaler(X_train, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Note: Until post-modelling, only train data will be used henceforth._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXPLORE\n",
    "PROJECT PLAN -> ACQUIRE -> PRE-PROCESS -> **EXPLORE** -> MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A. Find Correlations\n",
    "Between Features to Target, Features to Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Look at Descriptive Stats of train data.\n",
    "2. Check if square footage, no. of bathrooms, and no. of bedrooms (features, X) are statistically significant with property value (target, y).\n",
    "3. Find strength of Linear Correlations between features and target through Pearson's R and heatmap plot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DESCRIPTIVE STATISTICS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Merge scaled X train and y train data to have a full train dataset\n",
    "train_combined = scaled_X_train.copy()\n",
    "train_combined[\"propvalue\"] = y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_combined.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = sns.pairplot(train_combined, vars=[\"sqft\",\"bathcnt\",\"bedcnt\",\"propvalue\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CORRELATIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrsqft, psqft = stats.pearsonr(train_combined.sqft, train_combined.propvalue)\n",
    "corrbth, pbth = stats.pearsonr(train_combined.bathcnt, train_combined.propvalue)\n",
    "corrbed, pbed = stats.pearsonr(train_combined.bedcnt, train_combined.propvalue)\n",
    "\n",
    "pearsonr = [corrsqft, corrbth, corrbed]\n",
    "pval = [psqft, pbth, pbed]\n",
    "\n",
    "r_pval = pd.DataFrame({\"pearsonr\":pearsonr, \"pvalue\":pval})\n",
    "r_pval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,5))\n",
    "cor = train_combined.corr()\n",
    "sns.heatmap(cor, annot=True, cmap=plt.cm.Reds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TAKEAWAYS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Features to Target Correlations**\n",
    "- Square Footage on its own has a MODERATE POSITIVE correlation with Property Value\n",
    "- Bathroom Count on its own has a MODERATE POSITIVE correlation with Property Value\n",
    "- Bedroom Count on its own has a VERY LOW POSITIVE correlation with Property Value\n",
    "\n",
    "**Features to Features Correlations**\n",
    "- Square Footage and No. of Bathrooms have HIGH POSITIVE correlations with each other\n",
    "- Square Footage and No. of Bedrooms have MODERATE POSITIVE correlations with each other\n",
    "\n",
    "**Conclusion**  \n",
    "Multicollinearity is apparent among the three features. With the Bathroom and Bedroom Count showing High and Moderate Positive Correlations towards the other feature Square Footage, not addressing these correlations might affect fitting the train data to the linear regression model.\n",
    "\n",
    "To address this, PCA (Principal Component Analysis) will be used since PCA is designed to manage highly correlated variables by \"combining\" features linearly. Only the highest principal component, i.e., PC1 will be fed into the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### B. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=1, copy=True, whiten=False, svd_solver='auto', random_state=123)\n",
    "pca.fit(scaled_X_train)\n",
    "pc1 = pca.transform(scaled_X_train)\n",
    "pc1 = pd.DataFrame(X_pca)\n",
    "\n",
    "# print(pca.n_components_)\n",
    "# print(len(X))\n",
    "print(pca.explained_variance_ratio_)\n",
    "# print(X[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc1.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MODEL\n",
    "PROJECT PLAN -> ACQUIRE -> PRE-PROCESS -> EXPLORE -> **MODEL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lmo, lmo_intercept, lmo_coeff = util.generate_linear_model(pc1, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lmo.fit(pc1,y)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
